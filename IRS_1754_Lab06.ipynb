{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2203A51754/IRS/blob/main/IRS_1754_Lab06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###MONDAY\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "\n",
        "# Ensure you have downloaded the required NLTK data files\n",
        "nltk.download('punkt')\n",
        "# Download the 'punkt_tab' data package for word tokenization\n",
        "nltk.download('punkt_tab') # This line was added to download the necessary tokenizer data.\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase and tokenize\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return tokens\n",
        "def build_trigram_model(tokens):\n",
        "    model = defaultdict(Counter)\n",
        "    trigrams = ngrams(tokens, 3)\n",
        "    for w1, w2, w3 in trigrams:\n",
        "        model[(w1, w2)][w3] += 1\n",
        "    return model\n",
        "def calculate_probability(model, sequence):\n",
        "    sequence = sequence.lower().split()\n",
        "    prob = 1.0\n",
        "    for i in range(len(sequence) - 2):\n",
        "        w1, w2, w3 = sequence[i], sequence[i+1], sequence[i+2]\n",
        "        count_w3 = model[(w1, w2)][w3]\n",
        "        total_count = sum(model[(w1, w2)].values())\n",
        "        prob *= count_w3 / total_count if total_count > 0 else 0\n",
        "    return prob\n",
        "def generate_text(model, seed_words, length):\n",
        "    text = seed_words.lower().split()\n",
        "    for _ in range(length):\n",
        "        w1, w2 = text[-2], text[-1]\n",
        "        next_words = model.get((w1, w2), None)\n",
        "        if next_words:\n",
        "            next_word = random.choices(list(next_words.keys()), weights=next_words.values())[0]\n",
        "            text.append(next_word)\n",
        "        else:\n",
        "            break  # Cannot predict further\n",
        "    return ' '.join(text)\n",
        "# Sample text\n",
        "text = \"The quick brown fox jumps over the lazy dog. The quick brown fox is quick.\"\n",
        "\n",
        "tokens = preprocess_text(text)\n",
        "model = build_trigram_model(tokens)\n",
        "\n",
        "sequence = \"the quick brown\"\n",
        "probability = calculate_probability(model, sequence + \" fox\")\n",
        "print(f\"Probability of '{sequence} fox': {probability}\")\n",
        "\n",
        "generated_text = generate_text(model, \"the quick\", 5)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otMmHV-oJpQa",
        "outputId": "956e7859-94d5-4202-eac4-07632c048804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of 'the quick brown fox': 1.0\n",
            "Generated Text: the quick brown fox jumps over the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###TUESDAY\n",
        "def build_ngram_model(tokens, N):\n",
        "    model = defaultdict(Counter)\n",
        "    n_grams = ngrams(tokens, N)\n",
        "    for grams in n_grams:\n",
        "        context = grams[:-1]\n",
        "        word = grams[-1]\n",
        "        model[context][word] += 1\n",
        "    return model\n",
        "def calculate_perplexity(model, tokens, N):\n",
        "    N = max(N, 1)\n",
        "    n_grams = list(ngrams(tokens, N))\n",
        "    perplexity = 1\n",
        "    N_count = len(n_grams)\n",
        "    for grams in n_grams:\n",
        "        context = grams[:-1]\n",
        "        word = grams[-1]\n",
        "        total_count = sum(model[context].values())\n",
        "        word_count = model[context][word]\n",
        "        probability = word_count / total_count if total_count > 0 else 0\n",
        "        perplexity *= (1 / probability) if probability > 0 else 1\n",
        "    perplexity = pow(perplexity, 1 / N_count)\n",
        "    return perplexity\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def compare_ngram_models(tokens):\n",
        "    perplexities = []\n",
        "    Ns = range(1, 6)\n",
        "    for N in Ns:\n",
        "        model = build_ngram_model(tokens, N)\n",
        "        perp = calculate_perplexity(model, tokens, N)\n",
        "        perplexities.append(perp)\n",
        "\n",
        "    df = pd.DataFrame({'N-gram': list(Ns), 'Perplexity': perplexities})\n",
        "    sns.barplot(x='N-gram', y='Perplexity', data=df)\n",
        "    plt.title('N-gram Model Perplexity Comparison')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "wKMc38HsJssr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###WEDNESDAY\n",
        "import string\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "def generate_ngrams(tokens, N):\n",
        "    return list(ngrams(tokens, N))\n",
        "\n",
        "def get_ngram_frequencies(ngrams_list):\n",
        "    freq_dict = Counter(ngrams_list)\n",
        "    return freq_dict\n",
        "tokens = preprocess_text(text)\n",
        "\n",
        "for N in range(1, 4):\n",
        "    ngrams_list = generate_ngrams(tokens, N)\n",
        "    freq_dict = get_ngram_frequencies(ngrams_list)\n",
        "    print(f\"\\n{N}-grams Frequencies:\")\n",
        "    for ngram, freq in freq_dict.items():\n",
        "        print(f\"{ngram}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVYjV0h5J_x2",
        "outputId": "f404759d-3139-4d63-fbf9-19763a3ace33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1-grams Frequencies:\n",
            "('the',): 3\n",
            "('quick',): 3\n",
            "('brown',): 2\n",
            "('fox',): 2\n",
            "('jumps',): 1\n",
            "('over',): 1\n",
            "('lazy',): 1\n",
            "('dog',): 1\n",
            "('is',): 1\n",
            "\n",
            "2-grams Frequencies:\n",
            "('the', 'quick'): 2\n",
            "('quick', 'brown'): 2\n",
            "('brown', 'fox'): 2\n",
            "('fox', 'jumps'): 1\n",
            "('jumps', 'over'): 1\n",
            "('over', 'the'): 1\n",
            "('the', 'lazy'): 1\n",
            "('lazy', 'dog'): 1\n",
            "('dog', 'the'): 1\n",
            "('fox', 'is'): 1\n",
            "('is', 'quick'): 1\n",
            "\n",
            "3-grams Frequencies:\n",
            "('the', 'quick', 'brown'): 2\n",
            "('quick', 'brown', 'fox'): 2\n",
            "('brown', 'fox', 'jumps'): 1\n",
            "('fox', 'jumps', 'over'): 1\n",
            "('jumps', 'over', 'the'): 1\n",
            "('over', 'the', 'lazy'): 1\n",
            "('the', 'lazy', 'dog'): 1\n",
            "('lazy', 'dog', 'the'): 1\n",
            "('dog', 'the', 'quick'): 1\n",
            "('brown', 'fox', 'is'): 1\n",
            "('fox', 'is', 'quick'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###THURSDAY\n",
        "import re\n",
        "\n",
        "def preprocess_social_media_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Replace emojis with words (optional)\n",
        "    # Handle mentions and hashtags\n",
        "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
        "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
        "    # Expand abbreviations (optional)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "def build_ngram_model_with_smoothing(tokens, N):\n",
        "    model = defaultdict(Counter)\n",
        "    n_grams = ngrams(tokens, N)\n",
        "    vocabulary = set(tokens)\n",
        "    V = len(vocabulary)\n",
        "    for grams in n_grams:\n",
        "        context = grams[:-1]\n",
        "        word = grams[-1]\n",
        "        model[context][word] += 1\n",
        "\n",
        "    # Apply smoothing\n",
        "    for context in model:\n",
        "        total_count = sum(model[context].values())\n",
        "        for word in model[context]:\n",
        "            model[context][word] = (model[context][word] + 1) / (total_count + V)\n",
        "    return model\n",
        "import re\n",
        "import tokenize\n",
        "from io import BytesIO\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.util import ngrams\n",
        "import keyword\n",
        "\n",
        "# Sample code snippet\n",
        "code_sample = '''\n",
        "def factorial(n):\n",
        "    \"\"\"Compute the factorial of n\"\"\"\n",
        "    if n == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return n * factorial(n - 1)  # Recursive call\n",
        "'''\n",
        "\n",
        "def preprocess_code(code):\n",
        "    # Remove comments and docstrings\n",
        "    code_no_comments = re.sub(r'(\\\"\\\"\\\".*?\\\"\\\"\\\"|\\'\\'\\'.*?\\'\\'\\'|#.*$)', '', code, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "    tokens = []\n",
        "    try:\n",
        "        g = tokenize.tokenize(BytesIO(code_no_comments.encode('utf-8')).readline)\n",
        "        for toknum, tokval, _, _, _ in g:\n",
        "            if toknum == tokenize.ENDMARKER:\n",
        "                continue\n",
        "            elif toknum == tokenize.NUMBER:\n",
        "                tokens.append('<NUM>')\n",
        "            elif toknum == tokenize.STRING:\n",
        "                tokens.append('<STRING>')\n",
        "            elif toknum == tokenize.NAME:\n",
        "                if tokval in keyword.kwlist:\n",
        "                    tokens.append(tokval)\n",
        "                else:\n",
        "                    tokens.append('<VAR>')\n",
        "            else:\n",
        "                tokens.append(tokval)\n",
        "    except tokenize.TokenError as e:\n",
        "        print(f\"Tokenization error: {e}\")\n",
        "\n",
        "    return tokens\n",
        "tokens = preprocess_code(code_sample)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhHJ8-pyKJHF",
        "outputId": "5ea35f77-539a-403d-c598-24838767d633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['utf-8', '\\n', 'def', '<VAR>', '(', '<VAR>', ')', ':', '\\n', '\\n', '    ', 'if', '<VAR>', '==', '<NUM>', ':', '\\n', '        ', 'return', '<NUM>', '\\n', '', 'else', ':', '\\n', '        ', 'return', '<VAR>', '*', '<VAR>', '(', '<VAR>', '-', '<NUM>', ')', '', '', '']\n"
          ]
        }
      ]
    }
  ]
}